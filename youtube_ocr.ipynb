{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YouTube 弹幕 OCR 处理工作流\n",
        "\n",
        "本 Notebook 帮助你完成从 YouTube 下载带弹幕的视频、抽帧、OCR 识别、去重以及导出结构化数据的完整流程。请按照顺序运行每个单元，并在配置区修改参数以适配自己的项目需求。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装依赖\n",
        "\n",
        "- 运行下方命令安装所有需要的第三方库（重复运行也不会有副作用）。\n",
        "- 请提前在本地或服务器环境中安装好 `ffmpeg`，并确认它已加入 `PATH`；可以通过以下命令检查：\n",
        "\n",
        "```bash\n",
        "ffmpeg -version\n",
        "```\n",
        "\n",
        "若 `ffmpeg` 缺失，抽帧步骤会失败。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4418e708",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yt-dlp in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2025.11.12)\n",
            "Requirement already satisfied: paddlepaddle in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.2)\n",
            "Requirement already satisfied: paddleocr in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.2)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: pandas in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.7)\n",
            "Requirement already satisfied: httpx in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (2.2.6)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (6.33.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (12.0.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (3.5)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from paddlepaddle) (4.15.0)\n",
            "Requirement already satisfied: safetensors>=0.6.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (0.6.2)\n",
            "Requirement already satisfied: paddlex<3.4.0,>=3.3.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.3.9)\n",
            "Requirement already satisfied: PyYAML>=6 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (2.32.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: aistudio-sdk>=0.3.5 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.3.8)\n",
            "Requirement already satisfied: chardet in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (5.2.0)\n",
            "Requirement already satisfied: colorlog in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (6.10.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.1.4)\n",
            "Requirement already satisfied: modelscope>=1.28.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.32.0)\n",
            "Requirement already satisfied: prettytable in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.17.0)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.12.4)\n",
            "Requirement already satisfied: ruamel.yaml in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.18.16)\n",
            "Requirement already satisfied: ujson in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (5.11.0)\n",
            "Requirement already satisfied: imagesize in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.4.1)\n",
            "Requirement already satisfied: opencv-contrib-python==4.10.0.84 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: pyclipper in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.3.0.post6)\n",
            "Requirement already satisfied: pypdfium2>=4 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (5.0.0)\n",
            "Requirement already satisfied: python-bidi in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.6.7)\n",
            "Requirement already satisfied: shapely in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->paddleocr) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->paddleocr) (2.5.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (7.1.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (4.67.1)\n",
            "Requirement already satisfied: bce-python-sdk in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.9.52)\n",
            "Requirement already satisfied: click in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (8.3.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from modelscope>=1.28.0->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (65.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.4.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.10.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.2.0)\n",
            "Requirement already satisfied: shellingham in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.20.0)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from prettytable->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.2.14)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ruamel.yaml->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.2.15)\n",
            "Requirement already satisfied: pycryptodome>=3.8.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.23.0)\n",
            "Requirement already satisfied: future>=0.6.0 in c:\\users\\yingh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -U yt-dlp paddlepaddle paddleocr opencv-python pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dcfd8cb4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg already available on PATH: C:\\ffmpeg-8.0-full_build\\bin\\ffmpeg.EXE\n",
            "ffmpeg ready at: C:\\ffmpeg-8.0-full_build\\bin\\ffmpeg.EXE\n",
            "Checking current PATH entries...\n",
            "PATH already contains the ffmpeg directory.\n"
          ]
        }
      ],
      "source": [
        "# Install / verify ffmpeg availability\n",
        "import os\n",
        "import platform\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _run_command(cmd):\n",
        "    pretty = \" \".join(cmd)\n",
        "    print(f\"Running command: {pretty}\")\n",
        "    try:\n",
        "        subprocess.run(cmd, check=True)\n",
        "        return True\n",
        "    except Exception as exc:\n",
        "        print(f\"Command failed: {exc}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def ensure_ffmpeg():\n",
        "    existing = shutil.which(\"ffmpeg\")\n",
        "    if existing:\n",
        "        print(f\"ffmpeg already available on PATH: {existing}\")\n",
        "        return existing\n",
        "\n",
        "    print(\"ffmpeg is missing from PATH, trying automatic installation...\")\n",
        "    attempted = False\n",
        "\n",
        "    if shutil.which(\"conda\"):\n",
        "        attempted = True\n",
        "        if _run_command([\"conda\", \"install\", \"-y\", \"-c\", \"conda-forge\", \"ffmpeg\"]):\n",
        "            existing = shutil.which(\"ffmpeg\")\n",
        "            if existing:\n",
        "                return existing\n",
        "\n",
        "    system = platform.system().lower()\n",
        "\n",
        "    if system == \"linux\":\n",
        "        if shutil.which(\"apt-get\"):\n",
        "            attempted = True\n",
        "            _run_command([\"sudo\", \"apt-get\", \"update\"])\n",
        "            if _run_command([\"sudo\", \"apt-get\", \"install\", \"-y\", \"ffmpeg\"]):\n",
        "                existing = shutil.which(\"ffmpeg\")\n",
        "                if existing:\n",
        "                    return existing\n",
        "        if shutil.which(\"yum\"):\n",
        "            attempted = True\n",
        "            if _run_command([\"sudo\", \"yum\", \"install\", \"-y\", \"ffmpeg\"]):\n",
        "                existing = shutil.which(\"ffmpeg\")\n",
        "                if existing:\n",
        "                    return existing\n",
        "\n",
        "    elif system == \"darwin\":\n",
        "        if shutil.which(\"brew\"):\n",
        "            attempted = True\n",
        "            if _run_command([\"brew\", \"install\", \"ffmpeg\"]):\n",
        "                existing = shutil.which(\"ffmpeg\")\n",
        "                if existing:\n",
        "                    return existing\n",
        "\n",
        "    elif system == \"windows\":\n",
        "        if shutil.which(\"choco\"):\n",
        "            attempted = True\n",
        "            if _run_command([\"choco\", \"install\", \"ffmpeg\", \"-y\"]):\n",
        "                existing = shutil.which(\"ffmpeg\")\n",
        "                if existing:\n",
        "                    return existing\n",
        "        if shutil.which(\"winget\"):\n",
        "            attempted = True\n",
        "            if _run_command([\"winget\", \"install\", \"--id=Gyan.FFmpeg\", \"-e\", \"--source=winget\"]):\n",
        "                existing = shutil.which(\"ffmpeg\")\n",
        "                if existing:\n",
        "                    return existing\n",
        "\n",
        "    if not attempted:\n",
        "        print(\"No supported package manager was found. Install ffmpeg manually from https://ffmpeg.org/download.html\")\n",
        "    else:\n",
        "        print(\"Automatic installation attempts finished, but ffmpeg is still missing.\")\n",
        "\n",
        "    return shutil.which(\"ffmpeg\")\n",
        "\n",
        "\n",
        "ffmpeg_path = ensure_ffmpeg()\n",
        "if ffmpeg_path:\n",
        "    bin_dir = str(Path(ffmpeg_path).parent)\n",
        "    print(f\"ffmpeg ready at: {ffmpeg_path}\")\n",
        "    print(\"Checking current PATH entries...\")\n",
        "    entries = [p.strip() for p in os.environ.get(\"PATH\", \"\").split(os.pathsep) if p]\n",
        "    normalized_bin = str(Path(bin_dir).resolve())\n",
        "    normalized_entries = []\n",
        "    for entry in entries:\n",
        "        try:\n",
        "            normalized_entries.append(str(Path(entry).resolve()))\n",
        "        except Exception:\n",
        "            normalized_entries.append(entry)\n",
        "    if normalized_bin in normalized_entries:\n",
        "        print(\"PATH already contains the ffmpeg directory.\")\n",
        "    else:\n",
        "        os.environ[\"PATH\"] = bin_dir + os.pathsep + os.environ.get(\"PATH\", \"\")\n",
        "        print(\"Temporarily prepended the ffmpeg directory to PATH for this notebook session. Persist it manually if required.\")\n",
        "    subprocess.run([\"ffmpeg\", \"-version\"], check=False)\n",
        "else:\n",
        "    raise RuntimeError(\"ffmpeg is still unavailable. Please install it manually and rerun this cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4d845e",
      "metadata": {},
      "source": [
        "## 配置区\n",
        "\n",
        "在此集中维护所有可能需要修改的参数，后续模块会直接引用这些配置。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ca44c8f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 可调参数\n",
        "# ------------------------------\n",
        "YOUTUBE_URLS = [\n",
        "    \"https://www.youtube.com/watch?v=MC4A_GWj_sw&t=2s\",\n",
        "    # 可以继续追加更多链接\n",
        "]\n",
        "\n",
        "# 数据输出 / 缓存目录\n",
        "DOWNLOAD_DIR = \"./videos\"\n",
        "FRAMES_ROOT_DIR = \"./frames\"\n",
        "OUTPUT_DIR = \"./outputs\"\n",
        "\n",
        "# 是否直接复用 frames 目录中的已抽帧数据，跳过下载和抽帧\n",
        "USE_EXISTING_FRAMES_ONLY = True\n",
        "\n",
        "# 抽帧与 OCR 设置\n",
        "TARGET_FPS = 2.0  # 每秒抽取多少帧\n",
        "CROP_REGION = None  # 例如 (0, 0, 1920, 400)\n",
        "OCR_LANG = \"en\"  # PaddleOCR 语言\n",
        "MIN_OCR_SCORE = 0.6  # OCR 置信度阈值\n",
        "DEDUP_TIME_THRESHOLD = 1.0  # 去重允许的最大时间差（秒）\n",
        "RANDOM_SEED = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4e4938",
      "metadata": {},
      "source": [
        "## 公共导入与工具函数\n",
        "\n",
        "加载常用依赖并定义会在多个步骤中复用的辅助函数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0614933c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (9.7.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.14.3)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
            "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\yingh\\appdata\\roaming\\python\\python311\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
            "   ---------------------------------------- 0.0/139.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 139.8/139.8 kB 8.1 MB/s eta 0:00:00\n",
            "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
            "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
            "   ----------------------------- --------- 686.1/914.9 kB 21.1 MB/s eta 0:00:01\n",
            "   --------------------------------------- 914.9/914.9 kB 14.4 MB/s eta 0:00:00\n",
            "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------- ----------------------------- 0.6/2.2 MB 34.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.4/2.2 MB 17.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 20.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 17.5 MB/s eta 0:00:00\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -U ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1e8a66c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from paddleocr import PaddleOCR\n",
        "from yt_dlp import YoutubeDL\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "def ensure_dir(path: str) -> Path:\n",
        "    \"\"\"确保目录存在并返回对应的 Path 对象。\"\"\"\n",
        "    p = Path(path)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def sanitize_text(text: str) -> str:\n",
        "    \"\"\"去除文件名中常见的非法字符。\"\"\"\n",
        "    if not text:\n",
        "        return \"untitled\"\n",
        "    sanitized = re.sub(r'[\\\\/:\"*?<>|]+', \"_\", text).strip()\n",
        "    return sanitized or \"untitled\"\n",
        "\n",
        "FRAME_NAME_PATTERN = re.compile(r\"frame_(\\d+)\\.png$\", re.IGNORECASE)\n",
        "\n",
        "DOWNLOAD_DIR = ensure_dir(DOWNLOAD_DIR)\n",
        "FRAMES_ROOT_DIR = ensure_dir(FRAMES_ROOT_DIR)\n",
        "OUTPUT_DIR = ensure_dir(OUTPUT_DIR)\n",
        "\n",
        "VIDEO_INFOS: List[Dict] = []\n",
        "OCR_RESULTS: List[Dict] = []\n",
        "DEDUPED_OCR_RESULTS: List[Dict] = []\n",
        "OCR_RESULTS_DF: Optional[pd.DataFrame] = None\n",
        "OCR_ENGINE: Optional[PaddleOCR] = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5968146",
      "metadata": {},
      "source": [
        "## 下载视频\n",
        "\n",
        "使用 `yt-dlp` 下载目标视频，每个视频都会返回包含关键属性的字典，方便后续步骤引用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7a9cd7ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_youtube_video(url: str, download_dir: Path) -> Dict:\n",
        "    \"\"\"下载单个 YouTube 视频并返回其元信息。\"\"\"\n",
        "    download_dir = ensure_dir(download_dir)\n",
        "    ydl_opts = {\n",
        "        \"outtmpl\": str(download_dir / \"%(id)s.%(ext)s\"),\n",
        "        \"cookiesfrombrowser\": (\"chrome\",),  # Windows 上用 Chrome 的登录状态\n",
        "        # Force the lowest reasonable quality so smoke tests run quicker\n",
        "        \"format\": \"worstvideo[ext=mp4][height<=360]+worstaudio[ext=m4a]/worst[ext=mp4]/worst\",\n",
        "        \"merge_output_format\": \"mp4\",\n",
        "        \"restrictfilenames\": True,\n",
        "        \"noplaylist\": True,\n",
        "        \"quiet\": False,\n",
        "    }\n",
        "    try:\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            local_path = Path(ydl.prepare_filename(info)).resolve()\n",
        "            mp4_path = local_path.with_suffix(\".mp4\")\n",
        "            if mp4_path.exists():\n",
        "                local_path = mp4_path\n",
        "            video_id = sanitize_text(info.get(\"id\") or local_path.stem)\n",
        "            title = info.get(\"title\") or video_id\n",
        "            result = {\n",
        "                \"url\": url,\n",
        "                \"video_path\": str(local_path),\n",
        "                \"video_id\": video_id,\n",
        "                \"title\": title,\n",
        "            }\n",
        "            print(f\"[下载完成] {title} -> {local_path}\")\n",
        "            return result\n",
        "    except Exception as exc:\n",
        "        print(f\"[警告] 下载失败: {url}\\n原因: {exc}\")\n",
        "    return {}\n",
        "\n",
        "def download_all_videos(urls: List[str], download_dir: Path) -> List[Dict]:\n",
        "    \"\"\"批量下载多个视频，返回成功条目的列表。\"\"\"\n",
        "    if not urls:\n",
        "        print(\"未提供任何链接，请在配置区添加 YOUTUBE_URLS。\")\n",
        "        return []\n",
        "    collected: List[Dict] = []\n",
        "    for url in urls:\n",
        "        info = download_youtube_video(url, download_dir)\n",
        "        if info:\n",
        "            collected.append(info)\n",
        "    return collected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e38a5887",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting cookies from chrome\n",
            "Extracted 298 cookies from chrome\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=MC4A_GWj_sw&t=2s\n",
            "[youtube] MC4A_GWj_sw: Downloading webpage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: [youtube] Unable to download webpage: HTTP Error 429: Too Many Requests (caused by <HTTPError 429: Too Many Requests>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] MC4A_GWj_sw: Downloading initial data API JSON\n",
            "[youtube] MC4A_GWj_sw: Downloading iframe API JS\n",
            "[youtube] MC4A_GWj_sw: Downloading player b32979e9-main\n",
            "[youtube] MC4A_GWj_sw: Downloading tv downgraded player API JSON\n",
            "[youtube] MC4A_GWj_sw: Downloading web safari player API JSON\n",
            "[youtube] MC4A_GWj_sw: Downloading web player API JSON\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: [youtube] Unable to fetch GVS PO Token for tv_downgraded client: Missing required Data Sync ID for account. You may need to pass a Data Sync ID with --extractor-args \"youtube:data_sync_id=XXX\"\n",
            "WARNING: [youtube] MC4A_GWj_sw: Signature solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
            "WARNING: [youtube] MC4A_GWj_sw: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
            "WARNING: [youtube] Unable to fetch GVS PO Token for web_safari client: Missing required Data Sync ID for account. You may need to pass a Data Sync ID with --extractor-args \"youtube:data_sync_id=XXX\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] MC4A_GWj_sw: Downloading m3u8 information\n",
            "[info] MC4A_GWj_sw: Downloading 1 format(s): 91\n",
            "[download] Sleeping 5.00 seconds as required by the site...\n",
            "[hlsnative] Downloading m3u8 manifest\n",
            "[hlsnative] Total fragments: 2441\n",
            "[download] Destination: videos\\MC4A_GWj_sw.mp4\n",
            "[download]   0.5% of ~  69.95GiB at  321.60KiB/s ETA --:--:-- (frag 10/2441)"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mYOUTUBE_URLS 为空，请先在配置区补充链接。\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     VIDEO_INFOS = \u001b[43mdownload_all_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYOUTUBE_URLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDOWNLOAD_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m成功获取 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(VIDEO_INFOS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个视频。\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m VIDEO_INFOS:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mdownload_all_videos\u001b[39m\u001b[34m(urls, download_dir)\u001b[39m\n\u001b[32m     40\u001b[39m collected: List[Dict] = []\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     info = \u001b[43mdownload_youtube_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m     44\u001b[39m         collected.append(info)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mdownload_youtube_video\u001b[39m\u001b[34m(url, download_dir)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m YoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         info = \u001b[43mydl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m         local_path = Path(ydl.prepare_filename(info)).resolve()\n\u001b[32m     18\u001b[39m         mp4_path = local_path.with_suffix(\u001b[33m\"\u001b[39m\u001b[33m.mp4\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1685\u001b[39m, in \u001b[36mYoutubeDL.extract_info\u001b[39m\u001b[34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[39m\n\u001b[32m   1683\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached\n\u001b[32m   1684\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1685\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__extract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_info_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1687\u001b[39m     extractors_restricted = \u001b[38;5;28mself\u001b[39m.params.get(\u001b[33m'\u001b[39m\u001b[33mallowed_extractors\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1696\u001b[39m, in \u001b[36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1694\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1695\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1696\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (CookieLoadError, DownloadCancelled, LazyList.IndexError, PagedList.IndexError):\n\u001b[32m   1698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1852\u001b[39m, in \u001b[36mYoutubeDL.__extract_info\u001b[39m\u001b[34m(self, url, ie, download, extra_info, process)\u001b[39m\n\u001b[32m   1850\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[32m   1851\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_video(ie_result)\n\u001b[32m-> \u001b[39m\u001b[32m1852\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_ie_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ie_result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1911\u001b[39m, in \u001b[36mYoutubeDL.process_ie_result\u001b[39m\u001b[34m(self, ie_result, download, extra_info)\u001b[39m\n\u001b[32m   1909\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result_type == \u001b[33m'\u001b[39m\u001b[33mvideo\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1910\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_extra_info(ie_result, extra_info)\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m     ie_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_video_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_pending_errors(ie_result)\n\u001b[32m   1913\u001b[39m     additional_urls = (ie_result \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m'\u001b[39m\u001b[33madditional_urls\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3089\u001b[39m, in \u001b[36mYoutubeDL.process_video_result\u001b[39m\u001b[34m(self, info_dict, download)\u001b[39m\n\u001b[32m   3087\u001b[39m downloaded_formats.append(new_info)\n\u001b[32m   3088\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3089\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[32m   3091\u001b[39m     max_downloads_reached = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:189\u001b[39m, in \u001b[36m_catch_unsafe_extension_error.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _UnsafeExtensionError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    191\u001b[39m         \u001b[38;5;28mself\u001b[39m.report_error(\n\u001b[32m    192\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe extracted extension (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror.extension\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m) is unusual \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    193\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mand will be skipped for safety reasons. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    194\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you believe this is an error\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbug_reports_message(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3536\u001b[39m, in \u001b[36mYoutubeDL.process_info\u001b[39m\u001b[34m(self, info_dict)\u001b[39m\n\u001b[32m   3532\u001b[39m dl_filename = existing_video_file(full_filename, temp_filename)\n\u001b[32m   3533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dl_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dl_filename == temp_filename:\n\u001b[32m   3534\u001b[39m     \u001b[38;5;66;03m# dl_filename == temp_filename could mean that the file was partially downloaded with --no-part.\u001b[39;00m\n\u001b[32m   3535\u001b[39m     \u001b[38;5;66;03m# So we should try to resume the download\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3536\u001b[39m     success, real_download = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3537\u001b[39m     info_dict[\u001b[33m'\u001b[39m\u001b[33m__real_download\u001b[39m\u001b[33m'\u001b[39m] = real_download\n\u001b[32m   3538\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3278\u001b[39m, in \u001b[36mYoutubeDL.dl\u001b[39m\u001b[34m(self, name, info, subtitle, test)\u001b[39m\n\u001b[32m   3276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_info.get(\u001b[33m'\u001b[39m\u001b[33mhttp_headers\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3277\u001b[39m     new_info[\u001b[33m'\u001b[39m\u001b[33mhttp_headers\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m._calc_headers(new_info)\n\u001b[32m-> \u001b[39m\u001b[32m3278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtitle\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\common.py:479\u001b[39m, in \u001b[36mFileDownloader.download\u001b[39m\u001b[34m(self, filename, info_dict, subtitle)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.to_screen(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[download] Sleeping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_interval\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_note\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    477\u001b[39m     time.sleep(sleep_interval)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreal_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28mself\u001b[39m._finish_multiline_status()\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret, \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\hls.py:409\u001b[39m, in \u001b[36mHlsFD.real_download\u001b[39m\u001b[34m(self, filename, info_dict)\u001b[39m\n\u001b[32m    406\u001b[39m         \u001b[38;5;28mself\u001b[39m.download_and_append_fragments(\n\u001b[32m    407\u001b[39m             ctx, fragments, info_dict, pack_func=pack_fragment, finish_func=fin_fragments)\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_append_fragments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfragments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\fragment.py:513\u001b[39m, in \u001b[36mFragmentFD.download_and_append_fragments\u001b[39m\u001b[34m(self, ctx, fragments, info_dict, is_fatal, pack_func, finish_func, tpe, interrupt_trigger)\u001b[39m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     \u001b[43mdownload_fragment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfragment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     result = append_fragment(\n\u001b[32m    515\u001b[39m         decrypt_fragment(fragment, \u001b[38;5;28mself\u001b[39m._read_fragment(ctx)), fragment[\u001b[33m'\u001b[39m\u001b[33mfrag_index\u001b[39m\u001b[33m'\u001b[39m], ctx)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\fragment.py:462\u001b[39m, in \u001b[36mFragmentFD.download_and_append_fragments.<locals>.download_fragment\u001b[39m\u001b[34m(fragment, ctx)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    461\u001b[39m     ctx[\u001b[33m'\u001b[39m\u001b[33mfragment_count\u001b[39m\u001b[33m'\u001b[39m] = fragment.get(\u001b[33m'\u001b[39m\u001b[33mfragment_count\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_fragment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfragment\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequest_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPError, IncompleteRead) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\fragment.py:124\u001b[39m, in \u001b[36mFragmentFD._download_fragment\u001b[39m\u001b[34m(self, ctx, frag_url, info_dict, headers, request_data)\u001b[39m\n\u001b[32m    121\u001b[39m     frag_resume_len = \u001b[38;5;28mself\u001b[39m.filesize_or_none(\u001b[38;5;28mself\u001b[39m.temp_name(fragment_filename))\n\u001b[32m    122\u001b[39m fragment_info_dict[\u001b[33m'\u001b[39m\u001b[33mfrag_resume_len\u001b[39m\u001b[33m'\u001b[39m] = ctx[\u001b[33m'\u001b[39m\u001b[33mfrag_resume_len\u001b[39m\u001b[33m'\u001b[39m] = frag_resume_len\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m success, _ = \u001b[43mctx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfragment_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfragment_info_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\common.py:479\u001b[39m, in \u001b[36mFileDownloader.download\u001b[39m\u001b[34m(self, filename, info_dict, subtitle)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.to_screen(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[download] Sleeping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_interval\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_note\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    477\u001b[39m     time.sleep(sleep_interval)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreal_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28mself\u001b[39m._finish_multiline_status()\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret, \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\http.py:363\u001b[39m, in \u001b[36mHttpFD.real_download\u001b[39m\u001b[34m(self, filename, info_dict)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    362\u001b[39m     establish_connection()\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryDownload \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    365\u001b[39m     retry.error = err.source_error\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\downloader\\http.py:251\u001b[39m, in \u001b[36mHttpFD.real_download.<locals>.download\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    250\u001b[39m         \u001b[38;5;66;03m# Download and write\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m         data_block = \u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_len\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyte_counter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TransportError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    253\u001b[39m         retry(err)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\networking\\_requests.py:134\u001b[39m, in \u001b[36mRequestsResponseAdapter.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_real_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fp.closed:\n\u001b[32m    136\u001b[39m             \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\yt_dlp\\networking\\_requests.py:130\u001b[39m, in \u001b[36mRequestsResponseAdapter._real_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28miter\u001b[39m(read_chunk, \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Interact with urllib3 response directly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:467\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    471\u001b[39m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:599\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = chunk_left - amt\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m value.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    601\u001b[39m     amt -= chunk_left\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:638\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    632\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    633\u001b[39m \n\u001b[32m    634\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    636\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    640\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "if USE_EXISTING_FRAMES_ONLY:\n",
        "    frames_root = Path(FRAMES_ROOT_DIR)\n",
        "    VIDEO_INFOS = []\n",
        "    if frames_root.exists():\n",
        "        VIDEO_INFOS = [\n",
        "            {\"video_id\": p.name, \"video_path\": None, \"title\": p.name}\n",
        "            for p in frames_root.iterdir() if p.is_dir()\n",
        "        ]\n",
        "    print(f\"复用帧目录 {frames_root}，共检测到 {len(VIDEO_INFOS)} 个视频。\")\n",
        "elif not YOUTUBE_URLS:\n",
        "    print(\"YOUTUBE_URLS 为空，请先在配置区补充链接。\")\n",
        "else:\n",
        "    VIDEO_INFOS = download_all_videos(YOUTUBE_URLS, DOWNLOAD_DIR)\n",
        "    print(f\"成功获取 {len(VIDEO_INFOS)} 个视频。\")\n",
        "    for info in VIDEO_INFOS:\n",
        "        print(f\"- {info['video_id']}: {info['video_path']}\")\n",
        "\n",
        "if USE_EXISTING_FRAMES_ONLY and not VIDEO_INFOS:\n",
        "    print(\"未在 frames 目录发现已抽帧数据，请检查 FRAMES_ROOT_DIR 配置。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd57a241",
      "metadata": {},
      "source": [
        "## 抽帧（FFmpeg）\n",
        "\n",
        "利用 `ffmpeg` 按固定频率抽帧，可选地裁剪弹幕区域以减少噪音。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c77a178a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_frames_with_ffmpeg(video_path: str, frames_dir: Path, fps: float, crop_region: Optional[tuple] = None) -> None:\n",
        "    \"\"\"使用 ffmpeg 为单个视频抽帧并可选裁剪弹幕区域。\"\"\"\n",
        "    video_path = Path(video_path)\n",
        "    if not video_path.exists():\n",
        "        print(f\"[警告] 找不到视频文件: {video_path}\")\n",
        "        return\n",
        "    frames_dir = ensure_dir(frames_dir)\n",
        "    vf_parts = [f\"fps={fps}\"]\n",
        "    if crop_region:\n",
        "        try:\n",
        "            x, y, w, h = crop_region\n",
        "            vf_parts.append(f\"crop={w}:{h}:{x}:{y}\")\n",
        "        except ValueError:\n",
        "            print(f\"[警告] crop_region 格式应为 (x, y, w, h)，当前值: {crop_region}\")\n",
        "    vf = \",\".join(vf_parts)\n",
        "    output_pattern = frames_dir / \"frame_%06d.png\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-hide_banner\",\n",
        "        \"-loglevel\",\n",
        "        \"error\",\n",
        "        \"-i\",\n",
        "        str(video_path),\n",
        "        \"-vf\",\n",
        "        vf,\n",
        "        str(output_pattern),\n",
        "    ]\n",
        "    try:\n",
        "        subprocess.run(cmd, check=True)\n",
        "        print(f\"[抽帧完成] {video_path.name} -> {frames_dir}\")\n",
        "    except subprocess.CalledProcessError as exc:\n",
        "        print(f\"[错误] 抽帧失败: {video_path}\\n{exc}\")\n",
        "\n",
        "def extract_frames_for_all_videos(video_infos: List[Dict], frames_root_dir: Path, fps: float, crop_region: Optional[tuple] = None) -> None:\n",
        "    \"\"\"为所有视频生成帧，按照 video_id 建立子目录。\"\"\"\n",
        "    if not video_infos:\n",
        "        print(\"没有可处理的视频，请先完成下载。\")\n",
        "        return\n",
        "    for info in video_infos:\n",
        "        video_id = info.get(\"video_id\", \"unknown\")\n",
        "        video_path = info.get(\"video_path\")\n",
        "        if not video_path:\n",
        "            print(f\"[警告] 缺少视频路径: {info}\")\n",
        "            continue\n",
        "        frames_dir = Path(frames_root_dir) / video_id\n",
        "        extract_frames_with_ffmpeg(video_path, frames_dir, fps, crop_region)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "156eb883",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "暂无视频可抽帧。\n"
          ]
        }
      ],
      "source": [
        "if USE_EXISTING_FRAMES_ONLY:\n",
        "    print(\"已开启 USE_EXISTING_FRAMES_ONLY，跳过抽帧，直接使用 frames 目录。\")\n",
        "elif VIDEO_INFOS:\n",
        "    extract_frames_for_all_videos(VIDEO_INFOS, FRAMES_ROOT_DIR, TARGET_FPS, CROP_REGION)\n",
        "else:\n",
        "    print(\"暂无视频可抽帧。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b603081",
      "metadata": {},
      "source": [
        "## 复用已抽帧数据（免下载）\n",
        "\n",
        "如果 `./frames` 目录已经有抽好的帧，先运行此单元自动填充 `VIDEO_INFOS`，无需重复下载/抽帧。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7849e836",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    VIDEO_INFOS\n",
        "except NameError:\n",
        "    VIDEO_INFOS = []\n",
        "\n",
        "frames_root = Path(FRAMES_ROOT_DIR)\n",
        "if not frames_root.exists():\n",
        "    print(f\"[警告] 未找到帧目录: {frames_root.resolve()}\")\n",
        "elif not VIDEO_INFOS:\n",
        "    frame_ids = [p.name for p in frames_root.iterdir() if p.is_dir()]\n",
        "    VIDEO_INFOS = [\n",
        "        {\"video_id\": vid, \"video_path\": None, \"title\": vid}\n",
        "        for vid in frame_ids\n",
        "    ]\n",
        "    print(f\"[帧复用] 检测到 {len(VIDEO_INFOS)} 个帧目录: {', '.join(frame_ids)}\")\n",
        "else:\n",
        "    print(f\"[跳过] VIDEO_INFOS 已存在 {len(VIDEO_INFOS)} 条记录，未覆盖。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d1d2c3",
      "metadata": {},
      "source": [
        "## 初始化 OCR 引擎\n",
        "\n",
        "创建 PaddleOCR 全局实例，后续识别直接复用，避免重复加载模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f6ee10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 确保变量已定义，防止单独运行本单元时报 NameError\n",
        "try:\n",
        "    OCR_ENGINE\n",
        "except NameError:\n",
        "    OCR_ENGINE = None\n",
        "\n",
        "if OCR_ENGINE is None:\n",
        "    print(\"正在加载 PaddleOCR 模型，请稍候...\")\n",
        "    OCR_ENGINE = PaddleOCR(lang=OCR_LANG, use_textline_orientation=True)\n",
        "print(\"OCR 引擎已就绪。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb09b701",
      "metadata": {},
      "source": [
        "## OCR 识别帧中的弹幕\n",
        "\n",
        "逐帧调用 PaddleOCR 提取文本，并按照帧序号换算时间戳。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e149b02",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ocr_frames_in_dir(frames_dir: Path, fps: float, video_id: str, min_score: float = MIN_OCR_SCORE) -> List[Dict]:\n",
        "    \"\"\"对指定目录下的所有帧执行 OCR 并返回结果列表。\"\"\"\n",
        "    if OCR_ENGINE is None:\n",
        "        raise RuntimeError(\"请先初始化 OCR 引擎。\")\n",
        "    frames_dir = Path(frames_dir)\n",
        "    frame_files = sorted(frames_dir.glob(\"frame_*.png\"))\n",
        "    if not frame_files:\n",
        "        print(f\"[提示] 帧目录为空: {frames_dir}\")\n",
        "        return []\n",
        "    results: List[Dict] = []\n",
        "    for frame_path in frame_files:\n",
        "        match = FRAME_NAME_PATTERN.search(frame_path.name)\n",
        "        if not match:\n",
        "            continue\n",
        "        frame_index = int(match.group(1))\n",
        "        timestamp = (frame_index - 1) / fps\n",
        "        ocr_output = OCR_ENGINE.predict(str(frame_path), use_textline_orientation=True)\n",
        "        if not ocr_output:\n",
        "            continue\n",
        "        for line in ocr_output:\n",
        "            bbox_raw, (text, score) = line\n",
        "            text = text.strip()\n",
        "            if not text or score < min_score:\n",
        "                continue\n",
        "            bbox = [[float(point[0]), float(point[1])] for point in bbox_raw]\n",
        "            results.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"frame_index\": frame_index,\n",
        "                \"timestamp\": round(timestamp, 3),\n",
        "                \"text\": text,\n",
        "                \"score\": float(score),\n",
        "                \"bbox\": bbox,\n",
        "                \"frame_path\": str(frame_path),\n",
        "            })\n",
        "    print(f\"[OCR 完成] {video_id}: {len(results)} 条识别结果\")\n",
        "    return results\n",
        "\n",
        "def ocr_all_videos_frames(video_infos: List[Dict], frames_root_dir: Path, fps: float, min_score: float = MIN_OCR_SCORE) -> List[Dict]:\n",
        "    \"\"\"遍历所有视频的帧目录并聚合 OCR 结果。\"\"\"\n",
        "    aggregated: List[Dict] = []\n",
        "    for info in video_infos:\n",
        "        video_id = info.get(\"video_id\", \"unknown\")\n",
        "        frames_dir = Path(frames_root_dir) / video_id\n",
        "        if not frames_dir.exists():\n",
        "            print(f\"[警告] 找不到帧目录: {frames_dir}\")\n",
        "            continue\n",
        "        aggregated.extend(ocr_frames_in_dir(frames_dir, fps, video_id, min_score))\n",
        "    return aggregated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84378cee",
      "metadata": {},
      "outputs": [],
      "source": [
        "if VIDEO_INFOS:\n",
        "    OCR_RESULTS = ocr_all_videos_frames(VIDEO_INFOS, FRAMES_ROOT_DIR, TARGET_FPS, MIN_OCR_SCORE)\n",
        "    print(f\"共获得 {len(OCR_RESULTS)} 条 OCR 结果。\")\n",
        "else:\n",
        "    print(\"请先下载并抽帧后再进行 OCR。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 简单去重逻辑\n",
        "\n",
        "相邻帧可能重复识别同一条弹幕，以下函数按时间阈值过滤重复文本。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deduplicate_ocr_results(ocr_results: List[Dict], time_threshold: float = 1.0) -> List[Dict]:\n",
        "    \"\"\"基于 (video_id, text) 和时间差做简单去重。\"\"\"\n",
        "    if not ocr_results:\n",
        "        return []\n",
        "    sorted_results = sorted(ocr_results, key=lambda item: (item[\"video_id\"], item[\"timestamp\"]))\n",
        "    deduped: List[Dict] = []\n",
        "    last_seen: Dict[tuple, Dict] = {}\n",
        "    for item in sorted_results:\n",
        "        key = (item[\"video_id\"], item[\"text\"])\n",
        "        last_item = last_seen.get(key)\n",
        "        if last_item and (item[\"timestamp\"] - last_item[\"timestamp\"]) <= time_threshold:\n",
        "            continue\n",
        "        deduped.append(item)\n",
        "        last_seen[key] = item\n",
        "    return deduped\n",
        "\n",
        "DEDUPED_OCR_RESULTS = deduplicate_ocr_results(OCR_RESULTS, time_threshold=DEDUP_TIME_THRESHOLD)\n",
        "print(f\"去重前: {len(OCR_RESULTS)} 条 | 去重后: {len(DEDUPED_OCR_RESULTS)} 条\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 导出结构化数据\n",
        "\n",
        "使用 pandas 将结果写入 CSV：一个总表与若干按 `video_id` 分组的文件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_ocr_results(ocr_results: List[Dict], output_dir: Path) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"将 OCR 结果导出为 CSV 并返回 DataFrame。\"\"\"\n",
        "    output_dir = ensure_dir(output_dir)\n",
        "    if not ocr_results:\n",
        "        print(\"没有可导出的结果。\")\n",
        "        return None\n",
        "    df = pd.DataFrame(ocr_results)\n",
        "    base_cols = [\"video_id\", \"frame_index\", \"timestamp\", \"text\", \"score\", \"bbox\", \"frame_path\"]\n",
        "    ordered_cols = [col for col in base_cols if col in df.columns]\n",
        "    ordered_cols += [col for col in df.columns if col not in ordered_cols]\n",
        "    df = df[ordered_cols]\n",
        "    summary_csv = Path(output_dir) / \"all_videos_ocr_results.csv\"\n",
        "    df.to_csv(summary_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"总表已导出: {summary_csv}\")\n",
        "    for video_id, group in df.groupby(\"video_id\"):\n",
        "        video_csv = Path(output_dir) / f\"{video_id}_ocr_results.csv\"\n",
        "        group.to_csv(video_csv, index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"- {video_id} -> {video_csv}\")\n",
        "    return df\n",
        "\n",
        "OCR_RESULTS_DF = export_ocr_results(DEDUPED_OCR_RESULTS, OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 简单检查与可视化（可选）\n",
        "\n",
        "随机选取帧图并展示对应的 OCR 文本，帮助快速评估识别质量。若效果不佳，可尝试：\n",
        "- 调整 `CROP_REGION` 以确保只保留弹幕区域；\n",
        "- 调整 `TARGET_FPS` 以增大/减小采样密度；\n",
        "- 修改 `MIN_OCR_SCORE`，过滤掉低置信度结果；\n",
        "- 对帧图片做额外预处理（如二值化、锐化等），再重新识别。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not VIDEO_INFOS:\n",
        "    print(\"暂无可用视频，无法展示样例。\")\n",
        "elif OCR_RESULTS_DF is None or OCR_RESULTS_DF.empty:\n",
        "    print(\"暂无 OCR 结果，请先完成识别与导出步骤。\")\n",
        "else:\n",
        "    target_video = random.choice(VIDEO_INFOS)\n",
        "    frames_dir = Path(FRAMES_ROOT_DIR) / target_video[\"video_id\"]\n",
        "    frame_files = sorted(frames_dir.glob(\"frame_*.png\"))\n",
        "    if not frame_files:\n",
        "        print(f\"[提示] 帧目录为空: {frames_dir}\")\n",
        "    else:\n",
        "        sample_files = random.sample(frame_files, min(2, len(frame_files)))\n",
        "        print(f\"随机抽查视频: {target_video['title']} ({target_video['video_id']})\")\n",
        "        for frame_path in sample_files:\n",
        "            img = cv2.imread(str(frame_path))\n",
        "            if img is None:\n",
        "                print(f\"无法读取帧: {frame_path}\")\n",
        "                continue\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.axis('off')\n",
        "            plt.title(frame_path.name)\n",
        "            plt.show()\n",
        "            match = FRAME_NAME_PATTERN.search(frame_path.name)\n",
        "            frame_idx = int(match.group(1)) if match else None\n",
        "            if frame_idx is None:\n",
        "                print(\"无法解析帧编号。\\n\")\n",
        "                continue\n",
        "            subset = OCR_RESULTS_DF[\n",
        "                (OCR_RESULTS_DF['video_id'] == target_video['video_id']) &\n",
        "                (OCR_RESULTS_DF['frame_index'] == frame_idx)\n",
        "            ]\n",
        "            if subset.empty:\n",
        "                print(\"该帧未识别出文本。\\n\")\n",
        "            else:\n",
        "                for _, row in subset.iterrows():\n",
        "                    score_val = float(row['score']) if 'score' in row.index and pd.notna(row['score']) else float('nan')\n",
        "                    print(f\"- t={row['timestamp']:.2f}s | score={score_val:.2f} | {row['text']}\")\n",
        "                print()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
